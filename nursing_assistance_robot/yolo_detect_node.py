import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from geometry_msgs.msg import PointStamped
from cv_bridge import CvBridge
import cv2
from ultralytics import YOLO
import tf2_ros
import numpy as np # ArUco í¬ì¦ˆ ì¶”ì •ì— í•„ìš”
from visualization_msgs.msg import Marker
from std_msgs.msg import Bool 
from std_msgs.msg import Float64
from geometry_msgs.msg import Point
from rclpy.qos import QoSProfile, ReliabilityPolicy, DurabilityPolicy
import pickle
import os
from rokey_interfaces.msg import ArucoMarker
import subprocess
from geometry_msgs.msg import Twist
import time  # â† ì´ ì¤„ì„ ê¼­ ì¶”ê°€í•˜ì„¸ìš”

###############ì•„ë¥´ì½”ë§ˆì»¤#########################ì•„ë¥´ì½”ë§ˆì»¤#######################ì•„ë¥´ì½”ë§ˆì»¤########################ì•„ë¥´ì½”ë§ˆì»¤#########################ì•„ë¥´ì½”ë§ˆì»¤#####################################
#################ì•„ë¥´ì½”ë§ˆì»¤########################################ì•„ë¥´ì½”ë§ˆì»¤###################################################ì•„ë¥´ì½”ë§ˆì»¤########################################ì•„ë¥´ì½”ë§ˆì»¤##########
###############ì•„ë¥´ì½”ë§ˆì»¤#########################ì•„ë¥´ì½”ë§ˆì»¤#######################ì•„ë¥´ì½”ë§ˆì»¤########################ì•„ë¥´ì½”ë§ˆì»¤#########################ì•„ë¥´ì½”ë§ˆì»¤#####################################
#################ì•„ë¥´ì½”ë§ˆì»¤########################################ì•„ë¥´ì½”ë§ˆì»¤###################################################ì•„ë¥´ì½”ë§ˆì»¤########################################ì•„ë¥´ì½”ë§ˆì»¤##########
###############ì•„ë¥´ì½”ë§ˆì»¤#########################ì•„ë¥´ì½”ë§ˆì»¤#######################ì•„ë¥´ì½”ë§ˆì»¤########################ì•„ë¥´ì½”ë§ˆì»¤#########################ì•„ë¥´ì½”ë§ˆì»¤#####################################
#################ì•„ë¥´ì½”ë§ˆì»¤########################################ì•„ë¥´ì½”ë§ˆì»¤###################################################ì•„ë¥´ì½”ë§ˆì»¤########################################ì•„ë¥´ì½”ë§ˆì»¤##########
RGB_TOPIC ='/robot1/oakd/rgb/preview/image_raw'
CALIBRATION_FILE_PATH = 'camera_calibration.pkl' # ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
MARKER_SIZE = 0.05  # ArUco ë§ˆì»¤ í¬ê¸° (ë¯¸í„° ë‹¨ìœ„, ì˜ˆ: 5cm) - ì‹¤ì œ ë§ˆì»¤ í¬ê¸°ì™€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤!
class YoloSubscriber(Node):
    def __init__(self):
        super().__init__('yolo_subscriber')
        self.bridge = CvBridge()
        self.model = YOLO('/home/rokey/rokey_ws/src/rokey_pjt/rokey_pjt/best.pt',verbose=False)
        self.init_aruco()
        qos_profile = QoSProfile(
            reliability=ReliabilityPolicy.RELIABLE,
            durability=DurabilityPolicy.TRANSIENT_LOCAL,
            depth=10
        )
        self.rgb_subscription = self.create_subscription(
            Image,
            RGB_TOPIC,
            self.listener_callback,
            1)
        self.distance_subscription = self.create_subscription(
            Float64,
            '/distance',
            self.distance_callback,
            1
        )
        self.point_publisher = self.create_publisher(
            Point,
            '/depth_point',
            1
        )
        self.detected_marker_id_2 = False  # 2ë²ˆ ë§ˆì»¤ íŠ¸ë¦¬ê±° ì¤‘ë³µ ë°©ì§€ìš©
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)
        self.person_published = False
        self.person_cleared_published = False
        self.person_pub = self.create_publisher(Bool, '/person_detected', qos_profile)
        self.cleared_pub = self.create_publisher(Bool, '/person_cleared', qos_profile)
        self.marker_pub = self.create_publisher(ArucoMarker, '/aruco_marker', 10)
        self.no_person_frame_count = 0
        self.no_person_frame_threshold = 5 
        self.distance_m = None
        self.cmd_vel_pub = self.create_publisher(Twist, '/robot1/cmd_vel', 10)
        self.face_trigger_pub = self.create_publisher(Bool, '/face_detection_start', 10)
        self.face_triggered = False

       

    def init_aruco(self):
        # Aruco
        self.camera_matrix = None
        self.dist_coeffs = None
        try:
            # script_dir = os.path.dirname(os.path.abspath(__file__))
            # self.get_logger().info(script_dir)
            full_calibration_path = '/home/moon/nursing_assistance_robot/src/nursing_assistance_robot/nursing_assistance_robot/camera_calibration.pkl'
            with open(full_calibration_path, 'rb') as f:
                calibration_data = pickle.load(f)
            self.camera_matrix = calibration_data['camera_matrix']
            self.dist_coeffs = calibration_data['dist_coeffs']
            self.get_logger().info("ArUco: Calibration data loaded successfully.")
        except FileNotFoundError:
            self.get_logger().error(f"ArUco: Error: Camera calibration file not found at {full_calibration_path}")
            self.get_logger().error("ArUco: Please ensure 'camera_calibration.pkl' exists in the same directory as this script, or provide the full path.")
        except Exception as e:
            self.get_logger().error(f"ArUco: Error loading calibration data: {e}")  
        self.aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_5X5_250)
        self.aruco_params = cv2.aruco.DetectorParameters() 
        self.detector = cv2.aruco.ArucoDetector(self.aruco_dict, self.aruco_params)
        self.get_logger().info("ArUco: Detector initialized with DICT_5X5_250.")

        half_size = MARKER_SIZE / 2.0
        self.obj_points = np.array([
            [-half_size,  half_size, 0],  # Top-left
            [ half_size,  half_size, 0],  # Top-right
            [ half_size, -half_size, 0],  # Bottom-right
            [-half_size, -half_size, 0]   # Bottom-left
        ], dtype=np.float32)

    
    def listener_callback(self, msg):
        self.get_logger().info(f"YOLO ì‹œì‘ì¤‘")
        person_detected_now = False
        # ROS ì´ë¯¸ì§€ â†’ OpenCV ì´ë¯¸ì§€
        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
        self.frame_processed = cv_image.copy()
        # YOLO ì¶”ë¡ 
        results = self.model(cv_image, imgsz=320, conf=0.7)[0]
        annotated_frame = results.plot()  # ê²°ê³¼ ì‹œê°í™”
        if results.boxes is not None and results.boxes.xyxy is not None:
            for box, cls_id in zip(results.boxes.xyxy.cpu().numpy(), results.boxes.cls.cpu().numpy()):
                class_name = self.model.names[int(cls_id)]
                if class_name != 'wheelchair' and class_name != 'patient':
                    continue
                self.get_logger().info(f"class Name = ===== {class_name}")
                x1, y1, x2, y2 = box[:4]
                cx = int((x1 + x2) / 2)
                cy = int((y1 + y2) / 2)
                self.publish_point(cx,cy)
                if self.distance_m is not None:
                    if self.distance_m <= 3.0:
                        person_detected_now = True
                        if not self.person_published:
                            self.publish_person_detect()
                    else:
                        person_detected_now = False
        self.aruco_run()
        if person_detected_now:
            self.no_person_frame_count = 0  # ê°ì§€ëìœ¼ë©´ ì´ˆê¸°í™”
        else:
            if self.person_published:  # ì‚¬ëŒì´ ì´ì „ì— ê°ì§€ëœ ìƒíƒœì¼ ë•Œë§Œ ì²´í¬
                self.no_person_frame_count += 1
                if self.no_person_frame_count >= self.no_person_frame_threshold:
                    if not self.person_cleared_published:
                        self.publish_person_cleared()
                        self.person_cleared_published = True
                    self.no_person_frame_count = 0  # ì´ˆê¸°í™”
        cv2.imshow("YOLOv8 Detection", annotated_frame)
        cv2.waitKey(1)
    
    def aruco_run(self):
        if self.frame_processed is not None:
            frame_undistorted = cv2.undistort(self.frame_processed, self.camera_matrix, self.dist_coeffs)
            corners, ids, _ = self.detector.detectMarkers(frame_undistorted)
            if ids is not None:
                for i in range(len(ids)):
                    ret, rvec, tvec = cv2.solvePnP(
                        self.obj_points, corners[i],
                        self.camera_matrix, self.dist_coeffs
                    )
                    if not ret:
                        continue

                    marker_id = int(ids[i][0])

                    if marker_id == 2:
                        distance = float(tvec[2])
                        self.get_logger().info(f"ğŸ¯ ArUco ID=2 ê±°ë¦¬: {distance:.2f}m")

                        # âœ… 1m ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½í•˜ê³ , 1m ì´ìƒì´ë©´ ë°˜ë³µì ìœ¼ë¡œ ì „ì§„
                        if distance > 1.0:
                            self.get_logger().info("â¡ï¸ ê±°ë¦¬ 1m ì´ìƒ â†’ ì „ì§„ ì¤‘...")
                            self.forward_slightly()
                            self.face_triggered = False  # ê³„ì† ì´ˆê¸°í™”í•˜ì—¬ ë°˜ë³µ ê°€ëŠ¥í•˜ê²Œ í•¨
                        elif distance <= 1.0 and not self.face_triggered:
                            self.get_logger().info(f"ğŸ“ ì–¼êµ´ ì¸ì‹ ì‹œì‘ (ê±°ë¦¬={distance:.2f}m)")
                            self.trigger_face_detection()
                            self.face_triggered = True

                    # ë§ˆì»¤ ë©”ì‹œì§€ í¼ë¸”ë¦¬ì‹œ
                    rot_matrix, _ = cv2.Rodrigues(rvec)
                    try:
                        euler_angles = cv2.RQDecomp3x3(rot_matrix)[0]
                    except cv2.error:
                        self.get_logger().warn(f"ArUco: Rotation ì‹¤íŒ¨ - ID {ids[i][0]}")
                        continue
                    marker_msg = ArucoMarker()
                    marker_msg.id = int(ids[i][0])
                    marker_msg.pos_x = float(tvec[0])
                    marker_msg.pos_y = float(tvec[1])
                    marker_msg.pos_z = float(tvec[2])
                    marker_msg.rot_x = float(euler_angles[0])
                    marker_msg.rot_y = float(euler_angles[1])
                    marker_msg.rot_z = float(euler_angles[2])
                    self.marker_pub.publish(marker_msg)
        
    def distance_callback(self,msg:Float64):
        self.distance_m = msg.data
    def trigger_face_detection(self):
        self.get_logger().info("ğŸ¯ ì–¼êµ´ ì¸ì‹ ë° ì‹¬ë°•ìˆ˜ ë£¨í‹´ íŠ¸ë¦¬ê±°!")
        # ì˜ˆ: /face_detection_start í† í”½ ë°œí–‰ ë˜ëŠ” ì„œë¹„ìŠ¤ í˜¸ì¶œ
        msg = Bool()
        msg.data = True
        self.face_trigger_pub.publish(msg)  # í¼ë¸”ë¦¬ì…” ì„ ì–¸ í•„ìš”!

    def forward_slightly(self):
        twist = Twist()
        twist.linear.x = 0.07  # ì•„ì£¼ ì²œì²œíˆ
        start_time = time.time()
        while time.time() - start_time < 5:
            self.cmd_vel_pub.publish(twist)
            rclpy.spin_once(self, timeout_sec=0.1)
        twist.linear.x = 0.0
        self.cmd_vel_pub.publish(twist)

    

        # ğŸ’¡ vital_check_node2.py ì‹¤í–‰
        try:
        # ROS2 í™˜ê²½ì„ ì†Œì‹±í•œ í›„ vital ë…¸ë“œ ì‹¤í–‰
            subprocess.Popen([
                'bash', '-c',
                'source /opt/ros/humble/setup.bash && '
                'source ~/nursing_assistance/install/setup.bash && '
                'ros2 run nursing_assistance vital'
            ])
            print("ğŸ©º vital_check_node2 ì‹¤í–‰ë¨")
        except Exception as e:
            print(f"âŒ vital_check_node2 ì‹¤í–‰ ì‹¤íŒ¨: {e}")

    def publish_person_detect(self):
        msg = Bool()
        msg.data = True
        self.person_pub.publish(msg)
        self.get_logger().info('âœ… /person_detected â†’ True ë°œí–‰')
        self.person_published = True
        self.person_cleared_published = False

    def publish_person_cleared(self):
        msg = Bool()
        msg.data = True
        self.cleared_pub.publish(msg)
        self.get_logger().info('âš ï¸ /person_cleared â†’ True ë°œí–‰')

    def publish_point(self,cx:int,cy:int):
        point_msg = Point()
        point_msg.x = float(cx)
        point_msg.y = float(cy)
        point_msg.z = 0.0
        self.point_publisher.publish(point_msg)

    def point_transform(self,distance:float):
        point_base = PointStamped()
        point_base.header.stamp = rclpy.time.Time().to_msg()
        point_base.header.frame_id = 'base_link'
        point_base.point.x = distance
        point_base.point.y = 0.0
        point_base.point.z = 0.0
        if self.tf_buffer.can_transform('map', 'base_link', rclpy.time.Time(), timeout=rclpy.duration.Duration(seconds=1.0)):
            point_map = self.tf_buffer.transform(
                point_base,
                'map',
                timeout=rclpy.duration.Duration(seconds=0.5)
            )
            self.get_logger().info(f"[Map] ({point_map.point.x:.2f}, {point_map.point.y:.2f}, {point_map.point.z:.2f})")
            return point_base
        else:
            self.get_logger().warn('Transform from base_link to map is not available yet.')
            return None
    def transform_aruco_point_to_map_x(self, aruco_pos_x: float, aruco_pos_y: float, aruco_pos_z: float) -> float | None:
        """
        ì•„ë£¨ì½” ë§ˆì»¤ì˜ ì¹´ë©”ë¼ ì¢Œí‘œê³„ ìœ„ì¹˜ë¥¼ map ì¢Œí‘œê³„ë¡œ ë³€í™˜í•˜ê³ ,
        ë³€í™˜ëœ ì ì˜ x ì¢Œí‘œë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        aruco_point_camera = PointStamped()
        aruco_point_camera.header.stamp = self.get_clock().now().to_msg()
        # ì´ ë¶€ë¶„ì´ ì¤‘ìš”í•©ë‹ˆë‹¤. '/robot1/oakd/rgb/preview/image_raw' í† í”½ì˜ frame_idë¥¼ í™•ì¸í•˜ì—¬ ì •í™•íˆ ì…ë ¥í•˜ì„¸ìš”.
        # ì¼ë°˜ì ì¸ OAK-D ROS ë“œë¼ì´ë²„ì˜ conventionì— ë”°ë¼ 'robot1_oakd_rgb_camera_optical_frame' ë˜ëŠ” ìœ ì‚¬í•œ ì´ë¦„ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # ì •í™•í•œ ì´ë¦„ì€ `ros2 topic echo /robot1/oakd/rgb/preview/image_raw`ë¥¼ ì‹¤í–‰í•˜ì—¬ ë©”ì‹œì§€ì˜ `header.frame_id`ë¥¼ í™•ì¸í•˜ê±°ë‚˜,
        # `ros2 run tf2_tools view_frames` ëª…ë ¹ìœ¼ë¡œ TF íŠ¸ë¦¬ë¥¼ í™•ì¸í•˜ì—¬ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        aruco_point_camera.header.frame_id = 'robot1_oakd_rgb_camera_optical_frame' # <-- ì´ê³³ì„ ì‹¤ì œ ì¹´ë©”ë¼ í”„ë ˆì„ IDë¡œ ë³€ê²½!

        aruco_point_camera.point.x = aruco_pos_x
        aruco_point_camera.point.y = aruco_pos_y
        aruco_point_camera.point.z = aruco_pos_z

        try:
            point_map = self.tf_buffer.transform(
                aruco_point_camera,
                'map', # ëª©í‘œ ì¢Œí‘œê³„
                timeout=rclpy.duration.Duration(seconds=1.0) # ë³€í™˜ ëŒ€ê¸° ì‹œê°„
            )
            self.get_logger().info(f"ArUco ì›ë³¸ ({aruco_point_camera.point.x:.2f},{aruco_point_camera.point.y:.2f},{aruco_point_camera.point.z:.2f}) "
                                   f"ë¥¼ Mapìœ¼ë¡œ ë³€í™˜: ({point_map.point.x:.2f}, {point_map.point.y:.2f}, {point_map.point.z:.2f})")
            return point_map.point.x # ë³€í™˜ëœ ì ì˜ x ì¢Œí‘œë§Œ ë°˜í™˜

        except tf2_ros.TransformException as ex:
            self.get_logger().warn(f"ArUco: mapìœ¼ë¡œì˜ TF ë³€í™˜ ì‹¤íŒ¨: {ex}. Frame ID ('{aruco_point_camera.header.frame_id}') ë˜ëŠ” 'map' í”„ë ˆì„ì´ TF íŠ¸ë¦¬ì— ì—†ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return None
        except Exception as e:
            self.get_logger().error(f"ArUco: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
        
def main(args=None):
    rclpy.init(args=args)
    node = YoloSubscriber()
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        print('ì¢…ë£Œí•©ë‹ˆë‹¤.')
    node.destroy_node()
    rclpy.shutdown()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()
