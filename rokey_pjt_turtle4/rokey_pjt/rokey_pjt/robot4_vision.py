# robot4_vision.py

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CompressedImage, CameraInfo
from rokey_interfaces.srv import ObjectPosition
from geometry_msgs.msg import PointStamped
from visualization_msgs.msg import Marker
from cv_bridge import CvBridge
import tf2_ros
import tf2_geometry_msgs
import numpy as np
import cv2
import threading
import time
import os
import shutil
import sys
import csv
from ultralytics import YOLO
from pathlib import Path
import torch
import argparse
import math


# robot namespace ì§€ì •
ROBOT_NAMESPACE = 'robot4'

# topic ì´ë¦„ ì§€ì •
RGB_TOPIC = f'/{ROBOT_NAMESPACE}/oakd/rgb/image_raw'
RGB_TOPIC_COMPRESSED = f'/{ROBOT_NAMESPACE}/oakd/rgb/image_raw/compressed'
DEPTH_TOPIC = f'/{ROBOT_NAMESPACE}/oakd/stereo/image_raw'
CAMERA_INFO_TOPIC = f'/{ROBOT_NAMESPACE}/oakd/stereo/camera_info'
MARKER_TOPIC = f'/{ROBOT_NAMESPACE}/detected_objects_marker'

# raw, compressed ëª¨ë“œ ì„¤ì •
SUB_IMAGE_TYPE = 'compressed'
# SUB_IMAGE_TYPE = 'raw'

# YOLO confidence, model path
CONFIDENCE_THRESHOLD = 0.8
YOLO_PATH = '/home/hongha/YOLO Dataset_turtlebot4/runs/detect/yolov8s/weights/best.pt'

# ì¸ì‹ëœ ê°ì²´ì˜ ì‹œê°í™” ìƒ‰ìƒ
color_dict = {
    "bandage": (0, 255, 255),   # cyan (BGR)
    "codaewon": (0, 255, 0),    # lime/yellow-green (BGR)
    "cup": (0, 0, 255),         # red (BGR)
    "tylenol": (255, 0, 255)    # purple (BGR)
}


'''ê°ì²´ë¥¼ íƒì§€í•˜ê³  map ì¢Œí‘œë¥¼ ì¶”ì •í•œ í›„, navigation nodeì— ì„œë¹„ìŠ¤ responseë¥¼ ë°˜í™˜í•˜ëŠ” í´ë˜ìŠ¤'''
class Robot4Vision(Node):
    def __init__(self):
        super().__init__('robot4_vision')

        self.get_logger().info("ğŸ“· Vision Node ì‹œì‘!")

        # YOLO ê°ì²´ íƒì§€ ëª¨ë¸ ì´ˆê¸°í™”
        self.model = YOLO(YOLO_PATH)
        self.model.to('cuda' if torch.cuda.is_available() else 'cpu')
        self.get_logger().info("Using GPU for inference." if torch.cuda.is_available() else "Using CPU.")
        self.classNames = getattr(self.model, 'names', [])

        # CvBridge ì„¤ì •
        self.bridge = CvBridge()

        # ë‚´ë¶€ ìƒíƒœ ë³€ìˆ˜ ì •ì˜
        self.K = None
        self.latest_rgb = self.latest_depth = self.latest_rgb_msg = self.processed_frame = None
        self.lock = threading.Lock()
        self.should_shutdown = False

        # TF2 ì´ˆê¸°í™”
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)

        # ë§ˆì»¤ publisher ì„¤ì •
        self.marker_pub = self.create_publisher(Marker, MARKER_TOPIC, 10)
        self.marker_id = 0

        self.get_logger().info("ğŸ“· ì¹´ë©”ë¼ ëŒ€ê¸°ì¤‘ ...")

        # ì„¼ì„œ í† í”½ subscription ì„¤ì •
        self.create_subscription(Image, DEPTH_TOPIC, self.depth_callback, 1)
        self.create_subscription(CameraInfo, CAMERA_INFO_TOPIC, self.camera_info_callback, 1)

        # RGB ì´ë¯¸ì§€ í† í”½ subscription ì„¤ì •
        if SUB_IMAGE_TYPE == 'compressed':
            self.create_subscription(CompressedImage, RGB_TOPIC_COMPRESSED, self.rgb_callback, 1)
            self.get_logger().info(f"Subscribing to topics:\n  RGB: {RGB_TOPIC_COMPRESSED}\n  Depth: {DEPTH_TOPIC}\n  CameraInfo: {CAMERA_INFO_TOPIC}\n  MarkerPub: {MARKER_TOPIC}")
        elif SUB_IMAGE_TYPE == 'raw':
            self.create_subscription(Image, RGB_TOPIC, self.rgb_callback, 1)
            self.get_logger().info(f"Subscribing to topics:\n  RGB: {RGB_TOPIC}\n  Depth: {DEPTH_TOPIC}\n  CameraInfo: {CAMERA_INFO_TOPIC}\n  MarkerPub: {MARKER_TOPIC}")

        self.get_logger().info("ğŸ“· ì¹´ë©”ë¼ ì‹œì‘!")

        # GUIì— ì´ë¯¸ì§€ë¥¼ í¼ë¸”ë¦¬ì‹œí•˜ëŠ” publisher ìƒì„±
        self.detect_img_publisher = self.create_publisher(CompressedImage, '/robot4/detect_img', 1)

        # ì„œë¹„ìŠ¤ ì„œë²„ ì‹œì‘
        self.srv = self.create_service(ObjectPosition, '/object_position', self.object_position_callback)
        self.get_logger().info("âœ… /object_position ì„œë¹„ìŠ¤ ì„œë²„ ì‹œì‘")

        # ê°ì²´ ìœ„ì¹˜ ì„œë¹„ìŠ¤ ê´€ë ¨ ë³€ìˆ˜ ì´ˆê¸°í™”
        self.detect_mode = False
        self.detect_done = False
        self.detect_start_time = 0.0
        self.detect_time = 5.0

        # ë¼ë²¨, ë¼ë²¨ ì¢Œí‘œ ë³€ìˆ˜ ì´ˆê¸°í™”
        self.label = ''
        self.x = None
        self.y = None


    '''í´ë¼ì´ì–¸íŠ¸ì—ì„œ labelì„ requestë¥¼ ë°›ìœ¼ë©´, ê°ì²´ íƒì§€ í›„ ê°ì²´ì˜ ì¢Œí‘œë¥¼ responseí•˜ëŠ” í•¨ìˆ˜'''
    def object_position_callback(self, request, response):
        # depth subscribtion ì‹œì‘
        # self.create_depth_subscription()

        # ìš”ì²­ë°›ì€ ê°ì²´ ë¼ë²¨ ì €ì¥
        self.label = request.label.lower().strip()
        self.get_logger().info(f"ğŸ“¥ [ì„œë¹„ìŠ¤ ìš”ì²­ ìˆ˜ì‹ ] label='{self.label}'")

        self.get_logger().info(f"[INFO] YOLO ëª¨ë¸ ì‹œì‘!")

        # YOLO ì¸ì‹ ë£¨í”„ íŠ¸ë¦¬ê±°, ì¼ì • ì‹œê°„ì´ ì§€ë‚œ í›„ YOLO ì¢…ë£Œí•˜ë„ë¡ ì œì–´
        self.detect_mode = True
        self.detect_start_time = time.time()
        
        # YOLO ì¸ì‹ ì™„ë£Œ ëŒ€ê¸°
        while not self.detect_done:
            time.sleep(0.03)
            continue
        
        # ê²°ê³¼ë¥¼ ì‘ë‹µ ë©”ì‹œì§€ì— ì„¤ì •
        response.x = self.x
        response.y = self.y
        self.detect_done = False

        # ì‘ë‹µ ë°˜í™˜ ë° ë¡œê·¸ ì¶œë ¥
        self.get_logger().info(f"ğŸ“¤ [ì„œë¹„ìŠ¤ ì‘ë‹µ ë°˜í™˜] x={response.x} y={response.y}")

        return response


    '''ë‚´ë¶€ ì¹´ë©”ë¼ ìº˜ë¦¬ë¸Œë ˆì´ì…˜ ì •ë³´ë¥¼ ìˆ˜ì‹ í•˜ëŠ” í•¨ìˆ˜'''
    def camera_info_callback(self, msg):
        if self.K is None:
            self.K = np.array(msg.k).reshape(3, 3)
            self.get_logger().info(f"ğŸ“· CameraInfo: fx={self.K[0,0]:.2f}, fy={self.K[1,1]:.2f}, cx={self.K[0,2]:.2f}, cy={self.K[1,2]:.2f}")


    '''RGB ì´ë¯¸ì§€ë¥¼ ROS ë©”ì‹œì§€ì—ì„œ OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜'''
    def rgb_callback(self, msg):
        try:
            # ì´ë¯¸ì§€ ë©”ì‹œì§€ -> OpenCV ì´ë¯¸ì§€ ë³€í™˜
            if SUB_IMAGE_TYPE == 'compressed':
                np_arr = np.frombuffer(msg.data, np.uint8)
                img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            elif SUB_IMAGE_TYPE == 'raw':
                img = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')
            
            with self.lock:
                self.latest_rgb, self.latest_rgb_msg = img, msg

        except Exception as e:
            self.get_logger().error(f"RGB conversion error: {e}")


    '''ROS í† í”½ì—ì„œ ìˆ˜ì‹ ëœ ê¹Šì´ ì´ë¯¸ì§€ ë©”ì‹œì§€ë¥¼ OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜'''
    def depth_callback(self, msg):
        try:
            depth = self.bridge.imgmsg_to_cv2(msg, 'passthrough')
            with self.lock:
                self.latest_depth = depth
        except Exception as e:
            self.get_logger().error(f"Depth conversion error: {e}")


    '''TF2ë¥¼ í™œìš©í•˜ì—¬ ì¹´ë©”ë¼ ì¢Œí‘œê³„ì— ìˆëŠ” 3D í¬ì¸íŠ¸ë¥¼ map ì¢Œí‘œê³„ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜'''
    def transform_to_map(self, pt_camera: PointStamped, class_name: str):
        try:
            pt_map = self.tf_buffer.transform(pt_camera, 'map', timeout=rclpy.duration.Duration(seconds=0.5))
            x, y, z = pt_map.point.x, pt_map.point.y, pt_map.point.z
            self.get_logger().info(f"[TF] {class_name} â†’ map: (x={x:.2f}, y={y:.2f}, z={z:.2f})")
            return x, y, z
        except Exception as e:
            self.get_logger().warn(f"[TF] class={class_name} ë³€í™˜ ì‹¤íŒ¨: {e}")
            return float('nan'), float('nan'), float('nan')


    '''Marker ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ íŠ¹ì • ìœ„ì¹˜ì— ì‹œê°í™” ëª©ì ìœ¼ë¡œ í¼ë¸”ë¦¬ì‹œí•˜ëŠ” í•¨ìˆ˜'''
    def publish_marker(self, x, y, z, label):
        marker = Marker()
        marker.header.frame_id = 'map'
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns, marker.id = 'detected_objects', self.marker_id
        self.marker_id += 1
        marker.type, marker.action = Marker.SPHERE, Marker.ADD
        marker.pose.position.x, marker.pose.position.y, marker.pose.position.z = x, y, z
        marker.pose.orientation.w = 1.0
        marker.scale.x = marker.scale.y = marker.scale.z = 0.2
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 1.0, 1.0, 0.0, 1.0
        marker.lifetime.sec = 5
        self.marker_pub.publish(marker)


    '''ì‹¤ì‹œê°„ ì´ë¯¸ì§€ì— ëŒ€í•´ YOLOë¡œ ê°ì²´ë¥¼ ì¸ì‹í•˜ê³ , ì¸ì‹ëœ ê°ì²´ì˜ ì¢Œí‘œë¥¼ ì¶”ì •í•˜ëŠ” í•¨ìˆ˜'''
    def inference_loop(self):
        self.get_logger().info("Inference loop started. Waiting for images...")
        while rclpy.ok() and not self.should_shutdown:
            # ì´ë¯¸ì§€ ë° ì¹´ë©”ë¼ í–‰ë ¬ ì •ë³´ íšë“
            with self.lock:
                rgb, depth, K, rgb_msg = self.latest_rgb, self.latest_depth, self.K, self.latest_rgb_msg

            # ì•„ì§ ì´ë¯¸ì§€ ë˜ëŠ” ì •ë³´ê°€ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ëŒ€ê¸°
            if any(v is None for v in (rgb, depth, K, rgb_msg)):
                time.sleep(0.005)
                continue
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬
            frame = rgb.copy()

            # ì¸ì‹ ëª¨ë“œì¼ ë•Œ YOLO ì¶”ë¡  ì‹¤í–‰
            if self.detect_mode and self.model:
                results = self.model(frame, verbose=False)

                for result in results:
                    if result.boxes is None:
                        continue
                    for box in result.boxes:
                        # ë°”ìš´ë”© ë°•ìŠ¤ ì¤‘ì‹¬ ì¢Œí‘œ (í”½ì…€ ê¸°ì¤€)
                        u, v = map(int, box.xywh[0][:2].cpu().numpy())
                        if not (0 <= v < depth.shape[0] and 0 <= u < depth.shape[1]):
                            continue
                        
                        # ì‹ ë¢°ë„ í™•ì¸
                        conf = math.ceil(box.conf[0] * 100) / 100
                        if conf < CONFIDENCE_THRESHOLD:
                            continue
                        
                        # ê¹Šì´ ì •ë³´ë¥¼ ì‚¬ìš©í•´ 3D ìœ„ì¹˜ ì¶”ì • (camera ê¸°ì¤€)
                        # === [ì—¬ê¸° ìˆ˜ì •] ì£¼ë³€ í‰ê· ìœ¼ë¡œ z ê³„ì‚° ===
                        # v_min = max(0, v - 1)
                        # v_max = min(depth.shape[0], v + 2)
                        # u_min = max(0, u - 1)
                        # u_max = min(depth.shape[1], u + 2)

                        # patch = depth[v_min:v_max, u_min:u_max]
                        # z = np.nanmean(patch) / 1000.0

                        # if z <= 0 or np.isnan(z) or np.isinf(z):
                        #     continue
                        # === [ìˆ˜ì • ë] ì£¼ë³€ í‰ê· ìœ¼ë¡œ z ê³„ì‚° ===

                        z = float(depth[v, u]) / 1000.0
                        fx, fy = K[0, 0], K[1, 1]
                        cx, cy = K[0, 2], K[1, 2]
                        x = (u - cx) * z / fx
                        y = (v - cy) * z / fy

                        # ë¼ë²¨, ë°”ìš´ë”©ë°•ìŠ¤ ì¢Œí‘œ ì¶”ì¶œ
                        x1, y1, x2, y2 = map(int, box.xyxy[0].cpu().numpy())
                        conf = float(box.conf[0])
                        cls = int(box.cls[0])
                        label = self.classNames[cls] if cls < len(self.classNames) else f'class_{cls}'

                        # camera â†’ map ì¢Œí‘œê³„ ë³€í™˜
                        pt_camera = PointStamped()
                        pt_camera.header.frame_id = rgb_msg.header.frame_id
                        pt_camera.header.stamp = rgb_msg.header.stamp
                        # pt_camera.header.stamp = rclpy.time.Time().to_msg()
                        pt_camera.point.x, pt_camera.point.y, pt_camera.point.z = x, y, z
                        map_x, map_y, map_z = self.transform_to_map(pt_camera, label)
                        
                        # RViz ë§ˆì»¤ë¡œ ì‹œê°í™”
                        if not np.isnan(map_x):
                            self.publish_marker(map_x, map_y, map_z, label)

                        # ì´ë¯¸ì§€ì— ì‹œê°í™” ì •ë³´ ê·¸ë¦¬ê¸°
                        cv2.rectangle(frame, (x1, y1), (x2, y2), color_dict[label], 2)
                        cv2.circle(frame, (u, v), 4, color_dict[label], -1)
                        cv2.putText(frame, f"{label} {conf:.2f}", (x1, y1 - 35), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_dict[label], 2)
                        cv2.putText(frame, f"{z:.2f}m", (x1, y1 - 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_dict[label], 2)
                        cv2.putText(frame, f"({map_x:.2f}, {map_y:.2f}, {map_z:.2f})", (x1, y1 -5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_dict[label], 2)

                        # request ë°›ì€ ê°ì²´ë¼ë©´ ì¢Œí‘œ ì €ì¥
                        if label == self.label:
                            self.x = map_x
                            self.y = map_y

                # ì¼ì • ì‹œê°„ ê²½ê³¼ í›„ YOLO ëª¨ë¸ ì¢…ë£Œ
                elapsed = time.time() - self.detect_start_time
                if elapsed > self.detect_time:
                    self.get_logger().info(f"[INFO] YOLO ëª¨ë¸ {self.detect_time}ì´ˆ ê²½ê³¼, ë©”ëª¨ë¦¬ í•´ì œ ì¤‘...")
                    self.model = None
                    time.sleep(0.5)
                    self.detect_done = True
                    self.detect_mode = False
                    self.get_logger().info("[INFO] ì¸ì‹ ì¢…ë£Œ, YOLO ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ ì™„ë£Œ!")

            # frame (RGB) â†’ CompressedImage í¼ë¸”ë¦¬ì‹œ
            try:
                msg = CompressedImage()
                msg.header.stamp = self.get_clock().now().to_msg()
                msg.format = 'jpeg'
                # ret, jpeg = cv2.imencode('.jpg', cv2.cvtColor(frame, cv2.COLOR_RGB2BGR))
                ret, jpeg = cv2.imencode('.jpg', frame)
                if ret:
                    msg.data = jpeg.tobytes()
                    self.detect_img_publisher.publish(msg)
            except Exception as e:
                self.get_logger().error(f"ì´ë¯¸ì§€ í¼ë¸”ë¦¬ì‹œ ì˜¤ë¥˜: {e}")

            # ê²°ê³¼ í”„ë ˆì„ ì—…ë°ì´íŠ¸
            with self.lock:
                self.processed_frame = frame
            time.sleep(0.005)


def main():
    rclpy.init()
    node = Robot4Vision()

    try:
        threading.Thread(target=rclpy.spin, args=(node,), daemon=True).start()
        threading.Thread(target=node.inference_loop, daemon=True).start()

        while rclpy.ok() and not node.should_shutdown:
            with node.lock:
                frame = node.processed_frame.copy() if node.processed_frame is not None else None
            # if frame is not None:
            #     cv2.imshow("robot4_vision frame", frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                node.get_logger().info("Shutdown requested by user.")
                node.should_shutdown = True
                break
            time.sleep(0.01)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()
        cv2.destroyAllWindows()
        sys.exit(0)

if __name__ == '__main__':
    main()